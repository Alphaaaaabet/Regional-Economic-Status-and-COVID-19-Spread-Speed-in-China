{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that PIDs will be scraped from the public submission, but student names will be included.)\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [ x ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project aims to investigate issues surrounding the spread of the Novel Coronavirus(COVID-19) in mainland China. Our investigation primarily focuses on how each provinces’ economic status correlates to the number of maximum daily increase of infected patients confirmed in that region. \n",
    "\n",
    "We mainly used the ordinary least squares function to find numerical supports in exploring the correlations between factors associated with regional economy (measured in Gross Regional Product(GRP), GRP growth rate, income, and population density) and the control of COVID-19 in that region (measured by maximum daily increase of number of patients confirmed). We also visualized these correlations using scatter plots to give a more concise summary.\n",
    "\n",
    "We concluded that GRP, income and population density does positively correlate to the maximum daily increase of patients, while GRP growth rate doesn’t appear to influence the spread of COVID-19. We infer that these results are due to the fact that regions with more developed economies tend to have more interpersonal contact, therefore facilitating the spread of COVID-19.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Yang Li\n",
    "- Yiou Lyu\n",
    "- Linfeng Hu\n",
    "- Ruby Celeste Marroquin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A15560579\n",
    "- A15930345\n",
    "- A15473121\n",
    "- A16094382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the regional economic status of each province in mainland China correlate to its breakout and recovery of COVID-19?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your background and prior work here* \n",
    "\n",
    "References (include links):\n",
    "- 1)\n",
    "- 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your hypotheses here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Copy this information for each dataset)\n",
    "- Dataset Name: \n",
    "- Link to the dataset:\n",
    "- Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named shapely.geometry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-960f8c2373f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescartes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named shapely.geometry"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "\n",
    "import os\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import shapely.geometry as shp\n",
    "from shapely.geometry import Point, Polygon\n",
    "import descartes\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it came to cleaning our data, we decided to option for a generic approach: Represent our datasets in pandas DataFrames. After loading out datasets, we dropped *irrelevant* information -- when we say *irrelevant* we mean anything that doesn't pertain to what we are focusing on --  as well as any outliers in the data that may skew our results. We will also be renaming the columns to make it simpler when referencing/coding in our analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic Status Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the income per capita value for each province in mainland China. Income is measured in yuan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Income = pd.read_csv('Data/Income.csv')\n",
    "Income = Income.dropna(axis=1, how='all')\n",
    "#Income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the per capita Gross Regional Product value for each province. GRP per capita is measured in yuan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRP = pd.read_csv('Data/GRP.csv')\n",
    "GRP = GRP.dropna(axis=1, how='all')\n",
    "#GRP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Density Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population per province here is calculated in the unit of 10000 persons. It includes all residents (permanent/temporary; rural/urban) at the end of the year that is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('Data/Population.csv')\n",
    "population = population.dropna(axis = 1, how = 'all')\n",
    "#population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate population density of a region, we also need the areas of each province. Here, area of each province is measured in units of square kilometers.\n",
    "\n",
    "Since we only need the area information of each separate region, we will drop the \"Toal\" row at the end which contains information about the total area of China (judging by the data contained, the row name should be a typo). We will also drop the proportion row because we only need the area number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv('Data/Area.csv')\n",
    "area = area.dropna(axis = 1, how = 'all')\n",
    "#shorten column names to make following analysis simpler\n",
    "area = area.rename(columns={\"Area (sq.km)\": \"Area\"})\n",
    "area = area[area.District != 'Toal']\n",
    "area = area[area.columns[:2]]\n",
    "area = area.rename(columns = {'District':'Region'})\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remove \",\" in the string in order to change its datatype to int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comma(strin):\n",
    "    strin = strin.replace(',','')\n",
    "    return strin\n",
    "\n",
    "area['Area']= area['Area'].apply(remove_comma)\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Virus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read virus data into dataframes \n",
    "list_of_virus_data = list()\n",
    "\n",
    "# append data between Feb 1 and Feb 25 to list\n",
    "for i in range(20200201,20200226): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    list_of_virus_data.append(df)\n",
    "    \n",
    "# File 20200226.csv is missing, reason unknow. \n",
    "    \n",
    "# append data between Feb 27 and Feb 29 to list\n",
    "for i in range(20200227,20200230): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    list_of_virus_data.append(df)\n",
    "\n",
    "# append data between Mar 1 and  Mar 1 to list\n",
    "for i in range(20200301,20200302): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    list_of_virus_data.append(pd.read_csv(path))\n",
    "# access ith elment in the list using list_of_virus_data[i]\n",
    "# for example list_of_virus_data[0] gives the first dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Virus Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Used to clean Virus Data\n",
    "    \n",
    "The following functions were used to clean the csv files that were read in and contained various unecessary columns, characters, and such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces from string\n",
    "def remove_space(string):\n",
    "    try:\n",
    "        return string.replace(\" \",\"\")\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# Find the maximum numerical number in a row\n",
    "def find_max_in_a_row(df,row_index):\n",
    "    num_cols = df.shape[1]\n",
    "    max = 0\n",
    "    for i in range(0,num_cols):\n",
    "        value_in_ith_col = df.iloc[row_index,i]\n",
    "        try:\n",
    "            value_in_ith_col = remove_space(value_in_ith_col)\n",
    "            if (int(value_in_ith_col) > max):\n",
    "                max = int(value_in_ith_col)\n",
    "        except:\n",
    "            pass\n",
    "    return max\n",
    "\n",
    "# Find the maximum numerical numbers in each row of the dataframe, save them into df['max']\n",
    "def find_max_in_a_dataframe(df):\n",
    "    df['max'] = np.nan\n",
    "    for i in range(0,df.shape[0]):\n",
    "        df.loc[i,'max'] = find_max_in_a_row(df,i)\n",
    "        \n",
    "# Find the string in the data frame\n",
    "# Return row_index,col_index of the string if the string is found\n",
    "def find_string(df,string_to_find):\n",
    "    num_rows = df.shape[0]\n",
    "    num_cols = df.shape[1]\n",
    "    for row_index in range(0,num_rows):\n",
    "        for col_index in range(0,num_cols):\n",
    "            if (df.iloc[row_index,col_index] == string_to_find):\n",
    "                return row_index,col_index\n",
    "    raise Exception(\"string_to_find not found\") \n",
    "    return\n",
    "\n",
    "\n",
    "# Find \"Hubei\" in df\n",
    "# Return row_index,col_index of \"Hubei\" if \"Hubei\" is found\n",
    "def find_Hubei(df):\n",
    "    return find_string(df,\"Hubei\")\n",
    "\n",
    "def drop_population_column(df):\n",
    "    \n",
    "# drop column that contains '(10,000s)'\n",
    "    try:\n",
    "        target_string_3 = '(10,000s)'\n",
    "        target_string_3_col_index = find_string(df,target_string_3)[1]\n",
    "        df = df.drop(df.columns[target_string_3_col_index],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "# drop column that contains \"Population (in 10,000s)\"    \n",
    "    try:\n",
    "        target_string_1 = \"Population (in 10,000s)\"\n",
    "        target_string_1_col_index = find_string(df,target_string_1)[1]\n",
    "        df = df.drop(df.columns[target_string_1_col_index],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "# drop column that contains \"Population\"\n",
    "    try:\n",
    "        target_string_2 = \"Population\"\n",
    "        target_string_2_col_index = find_string(df,target_string_2)[1]\n",
    "        df =df.drop(df.columns[target_string_2_col_index],axis=1)\n",
    "    except:\n",
    "        return df\n",
    "    \n",
    "# index of \"Province/Region/City\" = col_index of Hubei\n",
    "# \"Confirmed Cases\" = max value in every row\n",
    "\n",
    "\n",
    "def clean_df_first_pass(df):\n",
    "    # find column index of \"Province/Region/City\"\n",
    "    city_col_index = find_Hubei(df)[1]\n",
    "    df[\"Province/Region/City\"] = df.iloc[:,city_col_index]\n",
    "    find_max_in_a_dataframe(df)\n",
    "    # Drop all rows above Hubei\n",
    "    for i in range(0, find_Hubei(df)[0]):\n",
    "        df = df.drop(i)\n",
    "    # Find out df[\"Confirmed Cases\"]\n",
    "    df[\"Confirmed Cases\"] = df['max']\n",
    "    df = df[[\"Province/Region/City\",\"Confirmed Cases\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def drop_rows_whose_city_length_too_long(df,max_length):\n",
    "    num_rows = df.shape[0]\n",
    "    for i in range(0,num_rows):\n",
    "        try:\n",
    "            city = df.loc[i,'Province/Region/City']\n",
    "            city_length = len(city)\n",
    "            if city_length > max_length:\n",
    "                df = df.drop(i)\n",
    "        except:\n",
    "            if not(np.isnan(city)):\n",
    "                raise Exception(\"fail to drop the \" + str(i) + \"th row, which is too long\")\n",
    "    return df\n",
    "\n",
    "def get_city_cases(df,region_name):\n",
    "    num_rows = df.shape[0]\n",
    "    return (df[df[\"Province/Region/City\"] == region_name][\"Confirmed Cases\"]).iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "def merge_one_day(day):\n",
    "    day_name = \"Day \" + str(day)\n",
    "    df[day_name] = np.nan\n",
    "    for i in range(0,df.shape[0]):\n",
    "        #print(i)\n",
    "        try:\n",
    "            region_name = df.loc[i,\"Province/Region/City\"]\n",
    "            num_cases = get_city_cases(list_of_virus_data[day],region_name)\n",
    "            df.loc[i,day_name] = num_cases\n",
    "        except:\n",
    "            df.loc[i,day_name] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Population Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_virus_data[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get population of each province/area from WHO Report\n",
    "population_from_WHO_report = list_of_virus_data[-1]\n",
    "population_from_WHO_report = population_from_WHO_report[['F1',\"Population\"]]\n",
    "\n",
    "# Clean population data\n",
    "population_from_WHO_report.columns = [\"Province/Region/City\",\"Population\" ]\n",
    "population_from_WHO_report = population_from_WHO_report.drop(0)\n",
    "population_from_WHO_report = population_from_WHO_report.drop(1)\n",
    "population_from_WHO_report = population_from_WHO_report.drop(2)\n",
    "population_from_WHO_report = population_from_WHO_report.drop(3)\n",
    "population_from_WHO_report =population_from_WHO_report.reset_index(drop=True)\n",
    "\n",
    "# Multiply populatino by 10000 for each province/region, since the unit is 10000\n",
    "population_from_WHO_report = population_from_WHO_report.astype({'Population': 'int'})\n",
    "population_from_WHO_report[\"Population\"] = population_from_WHO_report[\"Population\"] * 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Population Information from the dataframe about virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(list_of_virus_data)):\n",
    "    try:\n",
    "        list_of_virus_data[i] = drop_population_column(list_of_virus_data[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the First Few Files of virus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(list_of_virus_data)):\n",
    "    try:\n",
    "        list_of_virus_data[i] = clean_df_first_pass(list_of_virus_data[i])\n",
    "    except:\n",
    "        print(i)\n",
    "# get all the province names\n",
    "df = list_of_virus_data[0]\n",
    "for i in range (1,len(list_of_virus_data)):\n",
    "    df = df.merge(list_of_virus_data[i],on=\"Province/Region/City\",how='outer')\n",
    "df = df[[\"Province/Region/City\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows whose city name is too long or too short (because these rows are not data for cities, regions, or provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows whose city names are too long\n",
    "df = drop_rows_whose_city_length_too_long(df,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Virus Data\n",
    "    \n",
    "Merge all the dataframes in list_of_virus_data into a comprehensive one. Rows are province/area names, columns are the number of confirmed cases every day in that province/area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all confirmed cases into df\n",
    "for i in range(0,len(list_of_virus_data)):\n",
    "    merge_one_day(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing 0s with NaN for later cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill nan in df with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Province/Region/City whose name is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "    if (df.loc[i,'Province/Region/City'] == 0):\n",
    "        df = df.drop(i)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping irrelevant and confounding information\n",
    "Drop \"Total\". It is irrelvant to our further analysis. \n",
    "\n",
    "Drop \"Shanxi\". Because there are two provinces names \"shanxi\" in China. Their names are distinct in Chinese, but ambiguous in English. Thus, drop \"shanxi\" to reduce ambiguity. \n",
    "\n",
    "Drop 'MacaoSar' and 'MacaoSAR' since there's no confirmed case at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"Total\". It is irrelvant to our further analysis\n",
    "df = df.drop(df[df['Province/Region/City'] == \"Total\"].index[0])\n",
    "df = df.drop(df[df['Province/Region/City'] == \"Totals\"].index[0])\n",
    "\n",
    "# Drop \"shanxi\", because there are two provinces names \"shanxi\" in China. \n",
    "# Their names are distinct in Chinese, but ambiguous in English. \n",
    "# Thus, drop \"shanxi\" to reduce ambiguity. \n",
    "df = df.drop(df[df['Province/Region/City'] == \"Shanxi\"].index[0])\n",
    "\n",
    "# Drop 'MacaoSar' & 'MacaoSAR' since there's never a COVID-19 patient appear\n",
    "df = df.drop(df[df['Province/Region/City'] == \"MacaoSar\"].index[0])\n",
    "df = df.drop(df[df['Province/Region/City'] == \"MacaoSAR\"].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset df index\n",
    "df = df.reset_index(drop = True)\n",
    "df\n",
    "df.to_csv('merged_new_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning GeoSpatial Data\n",
    "\n",
    "\n",
    "The file being loaded in contains the longitude and latitude values of each country and its cities, regions, states, and/or provinces that have any confirmed cases; however, for our project, we will only be focusing on China as well as our 28 day period. The code following this cell removes any data that is not relevant to our project and is included in the csv file. I'd like to acknowledge that this file is taken from the public repository from John Hopkin's university and thank them for their continuous monitoring of the current situation in regards to the coronavirus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns and Rows\n",
    "\n",
    "Drops the countries that do not pertain to our analysis; any country that is not China. Drops the \"Country\" column since the remaining country is China. Drops Shaanxi and Shanxi because their names in English may be interpreted incorrectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load files with long and lat values\n",
    "coord_file = pd.read_csv('Data/covid_19_clean_complete.csv')\n",
    "coord_grp = pd.read_csv('Data/grp_lat_long.csv', index_col=None)\n",
    "#Drops the countries that aren't china\n",
    "new_data = coord_file.drop(coord_file[coord_file['Country/Region']!='Mainland China'].index)\n",
    "#Drop country column since it is only mainland china \n",
    "new_data = new_data.drop(columns='Country/Region')\n",
    "#Drop these because they are not relevant to our data\n",
    "new_data = new_data.drop(new_data[new_data['Province/State']=='Shaanxi'].index)\n",
    "new_data = new_data.drop(new_data[new_data['Province/State']=='Shanxi'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sub-DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = new_data.drop(new_data[new_data['Date']!='2/1/20'].index)\n",
    "first_date_exclude = first_date.drop(first_date[first_date['Province/State']=='Hubei'].index)\n",
    "last_date = new_data.drop(new_data[new_data['Date']!='3/1/20'].index)\n",
    "last_date_exclude = last_date.drop(last_date[last_date['Province/State']=='Hubei'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging GRP and Long/Lat DataFrames\n",
    "\n",
    "This merges the dataframes together and removes any remaining duplicates that may exist inside the DataFrame. Lastly, creates two new sub-dataframes one with Hubei and one excluding Hubei. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used later when displaying geospatial representation of GRP \n",
    "grp_coords = pd.concat([last_date,coord_grp], axis=0, ignore_index=True)\n",
    "#Drop Duplicates, keep last \n",
    "grp_coords.drop_duplicates(subset =\"Province/State\", keep = 'last', inplace = True)\n",
    "#Only really want to use GRP, lat, long, and province/state \n",
    "grp_coords = grp_coords[['Province/State', 'Lat', 'Long','GRP']]\n",
    "grp_coords_exclude = grp_coords.drop(grp_coords[grp_coords['Province/State']=='Hubei'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Shape File and Setting Up Geometry\n",
    "Load in the shapefile of China. Adjust the geometry according to each dataframe, as well as one for each including and excluding Hubei to further show how disproportinate it is and why we have decided to remove it. Finally creating our GeoDataFrame which allows us to plot on our China shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in China's shapefile \n",
    "china_province = gpd.read_file('Data/China_Province.shp')\n",
    "#Sets the geometry which is used in a GeoDataFrame for plotting points \n",
    "geometry = [Point(xy) for xy in zip(first_date['Long'], first_date['Lat'])]\n",
    "geometry2 = [Point(xy) for xy in zip(first_date_exclude['Long'], first_date_exclude['Lat'])]\n",
    "geometry3 = [Point(xy) for xy in zip(last_date['Long'], first_date['Lat'])]\n",
    "geometry4 = [Point(xy) for xy in zip(first_date_exclude['Long'], last_date_exclude['Lat'])]\n",
    "geometry5 = [Point(xy) for xy in zip(grp_coords['Long'], grp_coords['Lat'])]\n",
    "geometry6 = [Point(xy) for xy in zip(grp_coords_exclude['Long'], grp_coords_exclude['Lat'])]\n",
    "#Creates the geoframe datasets pertaining to their geometry \n",
    "geo_df = gpd.GeoDataFrame(first_date, crs={'init': 'epsg:4326'}, geometry=geometry)\n",
    "geo_df2 = gpd.GeoDataFrame(first_date_exclude, crs={'init': 'epsg:4326'}, geometry=geometry2)\n",
    "geo_df3 = gpd.GeoDataFrame(last_date, crs={'init': 'epsg:4326'}, geometry=geometry3)\n",
    "geo_df4 = gpd.GeoDataFrame(last_date_exclude, crs={'init': 'epsg:4326'}, geometry=geometry4)\n",
    "geo_df5 = gpd.GeoDataFrame(grp_coords, crs={'init': 'epsg:4326'}, geometry=geometry5)\n",
    "geo_df6 = gpd.GeoDataFrame(grp_coords_exclude, crs={'init': 'epsg:4326'}, geometry=geometry6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend of number of confirmed cases in each region (Hubei included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of number of confirmed cases in each region\n",
    "for i in range(0,df.shape[0]):\n",
    "    df.iloc[i,:][1:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend of number of confirmed cases in each region (Hubei excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of number of confirmed cases in each region (exclude Hubei)\n",
    "for i in range(1,df.shape[0]):\n",
    "    df.iloc[i,:][1:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Outbreak with Geography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying COVID-19 Exposure by Province\n",
    "    \n",
    "The left side of the graphs are used to represent all regions which have been affected by the coronavirus, including Hubei. As you can see the large circle that is shown is from Hubei because it contains the most cases by far surpassing any other province. In an effort to display more *precise* data, we will be excluding Hubei -- displayed on the right. From this we can see that the data is more concise and will allow for further and simpler analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(30, 15), constrained_layout=True)\n",
    "#plots the first date including hubei \n",
    "china_province.plot(ax=ax[0][0], color='black', alpha=0.82)\n",
    "geo_df.plot(column='Confirmed',ax=ax[0][0],markersize=first_date['Confirmed'], \n",
    "            color='red', marker='o', edgecolor='grey', alpha=0.5)\n",
    "#plots the first date exluding hubei \n",
    "china_province.plot(ax=ax[0][1], color='black', alpha=0.82)\n",
    "geo_df2.plot(column='Confirmed',ax=ax[0][1],markersize=first_date_exclude['Confirmed'], \n",
    "            color='red', marker='o', edgecolor='grey', alpha=0.5)\n",
    "#plots the last date including hubei \n",
    "china_province.plot(ax=ax[1][0], color='black', alpha=0.82)\n",
    "geo_df3.plot(column='Confirmed',ax=ax[1][0],markersize=last_date['Confirmed'], \n",
    "            color='red', marker='o', edgecolor='grey', alpha=0.5)\n",
    "#plots the last date excluding hubei \n",
    "china_province.plot(ax=ax[1][1], color='black', alpha=0.82)\n",
    "geo_df4.plot(column='Confirmed',ax=ax[1][1], markersize=last_date_exclude['Confirmed'], \n",
    "            color='red', marker='o', edgecolor='grey', alpha=0.5)\n",
    "#Labels the diagrams by inclusion/exclusion of Hubei \n",
    "ax[0][0].set_title(\"2/1/20: Coronavirus disease (COVID-19) - Including Hubei\")\n",
    "ax[0][1].set_title(\"2/1/20: Coronavirus disease (COVID-19) - Excluding Hubei\")\n",
    "ax[1][0].set_title(\"3/1/20: Coronavirus disease (COVID-19) - Including Hubei\")\n",
    "ax[1][1].set_title(\"3/1/20: Coronavirus disease (COVID-19) - Excluding Hubei\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind functions that will be used later when analysis correlation between income and maximum infection percentage\n",
    "\n",
    "# get the virus data of one city \n",
    "def get_virus_data_of_one_city(city):\n",
    "    # find row index of the city in df\n",
    "    row_index = find_string(df,city)[0]\n",
    "    # get data of the desired city using row index\n",
    "    city_data = df.iloc[row_index,:]\n",
    "    # remove city name from city_data\n",
    "    city_data = city_data[1:]\n",
    "    return city_data\n",
    "\n",
    "def get_population_data_of_one_city(city):\n",
    "    # find row index of the city in df\n",
    "    row_index = find_string(population_from_WHO_report,city)[0]\n",
    "    # get population data of the desired city using row index\n",
    "    city_population = population_from_WHO_report.iloc[row_index,1]\n",
    "    return city_population\n",
    "\n",
    "def calculate_infection_percentage_of_one_city(city):\n",
    "    infected_number = get_virus_data_of_one_city(city)\n",
    "    population = get_population_data_of_one_city(city)\n",
    "    return infected_number/population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate correlation between income and maximum infection percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate infection percentage and maximum infection percentage of each region\n",
    "\n",
    "\n",
    "        infection_percentage = confiremed cases / population\n",
    "        maximum infection percentage = max(infection_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funtions Caclulating infection percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate infection percentage\n",
    "infection_percentage = df\n",
    "row_index_of_regions_without_population = list()\n",
    "for row in range(0,infection_percentage.shape[0]):\n",
    "    city_name = infection_percentage.iloc[row,0]\n",
    "    try:\n",
    "        city_population = get_population_data_of_one_city(city_name)\n",
    "        for column in range(1,infection_percentage.shape[1]):\n",
    "            infection_percentage.iloc[row,column] = infection_percentage.iloc[row,column]/city_population\n",
    "    except:\n",
    "        row_index_of_regions_without_population.append(row)\n",
    "for i in range (0,len(row_index_of_regions_without_population)):\n",
    "    infection_percentage = infection_percentage.drop(row_index_of_regions_without_population[i])\n",
    "infection_percentage = infection_percentage.reset_index(drop=True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the maximum infection percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the maximum numerical number in a row\n",
    "def find_row_max(df,row_index):\n",
    "    num_cols = df.shape[1]\n",
    "    max = 0.0\n",
    "    for i in range(1,num_cols):\n",
    "        value_in_ith_col = df.iloc[row_index,i]\n",
    "        if (float(value_in_ith_col) > max):\n",
    "            max = float(value_in_ith_col)\n",
    "    return max\n",
    "\n",
    "# Find the maximum numerical numbers in each row of the dataframe, save them into df['max']\n",
    "def find_max(df):\n",
    "    df['max'] = np.nan\n",
    "    for i in range(0,df.shape[0]):\n",
    "        df.loc[i,'max'] = find_row_max(df,i)\n",
    "\n",
    "find_max(infection_percentage)\n",
    "max_infection_percentage = infection_percentage[['Province/Region/City','max']]\n",
    "max_infection_percentage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between max infection percentage and income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Hubei and try to find correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = Income\n",
    "income = income[['Region','2018']]\n",
    "income.columns = [\"Province/Region/City\",\"income\"]\n",
    "income.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = income.merge(max_infection_percentage,how=\"inner\")\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.corr()\n",
    "outcome, predictors = patsy.dmatrices('max ~ income', analysis_df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Outputs\n",
    "p_value is too large, we fail to reject the hypothesis that maximum infection percentage of a region is uncorrelated to the people's income in that region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Hubei and try to find corrlation again\n",
    "\n",
    "As we've seen before, there appears to be no apparent corelation between maximun infection percentage of a region and the citizens' income. However, we must also consider the extreme outlier -- \"Hubei\" province. This province is where COVID-19 first broke out, and there have been special treatments and distinguished governmental interventions placed for this province. Therefore, to diminish such comfounds and come up with a more precise correlation relationship. We decide to drop the observation of Hubei province\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row that contains \"Hubei\"\n",
    "row_index_of_Hubei = find_Hubei(analysis_df)[0]\n",
    "analysis_df = analysis_df.drop(row_index_of_Hubei)\n",
    "analysis_df = analysis_df.reset_index(drop = True)\n",
    "\n",
    "# Do OLS again\n",
    "outcome, predictors = patsy.dmatrices('max ~ income', analysis_df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret output\n",
    "Let alpha = 0.05. Since p_value (0.013) is small, we can reject the hypothesis that income is not correlated with maximum infection percentage of a region. We conclude that maxmum infection percentage of an area is correlated with people's income in that area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the model fit line\n",
    "\n",
    "# Plot the orginal data (as before)\n",
    "plt.scatter(analysis_df['income'], analysis_df['max'], alpha=0.3, label='Data');\n",
    "\n",
    "# Generate and plot the model fit line\n",
    "xs = np.arange(analysis_df['income'].min(), analysis_df['income'].max())\n",
    "ys = 2.541e-10 * xs\n",
    "plt.plot(xs, ys, '--k', linewidth=4, label='Model')\n",
    "\n",
    "plt.xlabel('Maximum Infection percentage')\n",
    "plt.xlabel('Income per capita (Yuan)')\n",
    "plt.legend()\n",
    "plt.ylim()\n",
    "plt.ylim(top = 0.00003)\n",
    "plt.ylim(bottom = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret output\n",
    "\n",
    "After excluding Hubei, even though we concluded that income does correlate with maximum infection percentage in a region, we cannot establish the relatioship between them very well using the above linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the \"province/region/city\" column to align with other dataframes and make it easier for later analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Province/Region/City':'Region'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Regional Gross Product(GRP) on COVID-19 outbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the ordinary least sqaures regression model(ols model) to figure out the correlation between GRP and COVID-19 breakout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single out the GRP in 2018 for each province \n",
    "GRP_2018 = GRP[GRP.columns[:2]]\n",
    "#rename max_infection_percentage's region column for later merge\n",
    "max_infection_percentage_1 = max_infection_percentage.rename(columns = {'Province/Region/City':'Region'})\n",
    "#merge virus breakout rate data with GRP dataframe by province\n",
    "GRP_virus = pd.merge(GRP_2018, max_infection_percentage_1, on = 'Region')\n",
    "#rename the columns to be more meaningful and easier for further analyses\n",
    "GRP_virus = GRP_virus.rename(columns = {'2018':'GRP'})\n",
    "GRP_virus = GRP_virus.rename(columns = {'CAGR':'virus'})\n",
    "GRP_virus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use an Ordinary Least Squares model to see the correlations between virus breakout rate and GRP in 2018 for each provinces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the outcome and what we use to predict using pasty\n",
    "outcome1, predictors1 = patsy.dmatrices('max ~ GRP', GRP_virus)\n",
    "# Now use statsmodels to intialize an OLS linear model\n",
    "# This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod_GRP = sm.OLS(outcome1, predictors1)\n",
    "# fit the model\n",
    "res_GRP = mod_GRP.fit()\n",
    "# Check out the results\n",
    "print(res_GRP.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the correlation seems vague since we have a large p-value of 0.948. \n",
    "\n",
    "Now, we try to find the correlation again while exclude the case of \"Hubei\" province just as in the above section where we interpret relationship between income and virus breakout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop observation in Hubei\n",
    "GRP_virus = GRP_virus[GRP_virus.Region != 'Hubei']\n",
    "#set up the outcome and what we use to predict using pasty\n",
    "o1, p1 = patsy.dmatrices('max ~ GRP', GRP_virus)\n",
    "# Now use statsmodels to intialize an OLS linear model\n",
    "# This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod_GRP_dropped = sm.OLS(o1, p1)\n",
    "# fit the model\n",
    "res_GRP_dropped = mod_GRP_dropped.fit()\n",
    "# Check out the results\n",
    "print(res_GRP_dropped.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpret results from OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, p-value here is 0.023, smaller than the general alpha value of 0.05. Therefore we can reject the hypothesis that GRP is not correlated with maximum infection percentage of a region. It's statistically significant to conclude that the maximum infection percentage of an area is correlated with GRP per capita in that area.\n",
    "\n",
    "Now we visualize such relationship between GRP in 2018 to the breakout rate of COVID-19.\n",
    "\n",
    "Use polyfit to fit a 1-degree linear model, predicting virus breakout rate from GRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the orginal data (as before)\n",
    "plt.scatter(GRP_virus['GRP'], GRP_virus['max'], alpha=0.3, label='Data');\n",
    "\n",
    "# Generate and plot the model fit line\n",
    "xs = np.arange(GRP_virus['GRP'].min(), GRP_virus['GRP'].max())\n",
    "# use the coefficient from OLS summary above\n",
    "ys = 9.272e-11 * xs\n",
    "plt.plot(xs, ys, '--k', linewidth=4, label='Model')\n",
    "\n",
    "plt.xlabel('GRP per capita \\n (yuan)')\n",
    "plt.ylabel('Maximum Infected percentage \\n %')\n",
    "plt.legend()\n",
    "plt.ylim()\n",
    "plt.ylim(top = 0.00003)\n",
    "plt.ylim(bottom = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore the correlation between the growth of GRP over the past 3 years in each province and the virus breakout rate\n",
    "\n",
    "We calculate the Annual growth of GRP over 3 years according to the following formula:\n",
    "        \n",
    "        (GRP_new - GRP_old)/GRP_old\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column annual GRP growth for the past 3 years of each province applying above formula\n",
    "GRP['growth'] = (GRP['2018'] - GRP['2016']) / GRP['2016']\n",
    "#single out\n",
    "GRP_growth = GRP[['Region','growth']]\n",
    "#merge the virus breakout rate data with GRP  growth rate by province\n",
    "GRP_growth_virus = pd.merge(GRP_growth, max_infection_percentage_1, on = 'Region')\n",
    "GRP_growth_virus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use OLS model to see if GRP growth rate over the past 3 years is correlated with virus breakout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the outcome and what we use to predict using pasty\n",
    "outcome2, predictors2 = patsy.dmatrices('max ~ growth', GRP_growth_virus)\n",
    "# Now use statsmodels to initialize an OLS linear model\n",
    "# This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod_GRP_growth = sm.OLS(outcome2, predictors2)\n",
    "# fit the model\n",
    "res_GRP_growth = mod_GRP_growth.fit()\n",
    "# Check out the results\n",
    "print(res_GRP_growth.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we fail to reject the null hypothesis as p-value as large as 0.470. But that doesn't mean there's actually no correlation between GRP growth rate and virus breakout. We understand that Hubei is still a potentially extremely powerful outlier here. Therefore, we try to exclude Hubei again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop observation in Hubei\n",
    "GRP_growth_virus = GRP_growth_virus[GRP_growth_virus.Region != 'Hubei']\n",
    "#set up the outcome and what we use to predict using pasty\n",
    "o3, p3 = patsy.dmatrices('max ~ growth', GRP_growth_virus)\n",
    "# Now use statsmodels to initialize an OLS linear model\n",
    "# This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod_growth_dropped = sm.OLS(o3, p3)\n",
    "# fit the model\n",
    "res_growth_dropped = mod_growth_dropped.fit()\n",
    "# Check out the results\n",
    "print(res_growth_dropped.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpret results from OLS model about GRP per capita growth rate and virus breakout rate\n",
    "Unfortunately, the p-value of 0.560 is still rather large, which implies that the outlier of Hubei is not the factor that influenced our investigation. GRP per capita growth rate should trully be considered uncorrelated to the virus breakout rate. We shall have more discussion about possible reasons leading up to this result in the discussion section at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising GRP of each provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax2) = plt.subplots(ncols=2, figsize=(30,15), sharey=True)\n",
    "#Displays the GRP of each affected region using the last date (includes Hubei)\n",
    "china_province.plot(ax=ax, color='black', alpha=0.82)\n",
    "geo_df5.plot(column='GRP',ax=ax, cmap='cool', marker='s', edgecolor='grey', \n",
    "             legend=True, markersize=450, alpha=0.6)\n",
    "#Displays the GRP of each affected region using the last date (excludes Hubei)\n",
    "china_province.plot(ax=ax2, color='black', alpha=0.82)\n",
    "geo_df6.plot(column='GRP',ax=ax2, cmap='cool', marker='s', edgecolor='grey', \n",
    "             markersize=450, legend=True, alpha=0.6)\n",
    "ax.set_title(\"GRP 2018 - Including Hubei\")\n",
    "ax2.set_title(\"GRP 2018 - Including Hubei\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of population density on COVID-19 Outbreak (as co-factor)\n",
    "\n",
    "### Correlation between Population density and economic status\n",
    "\n",
    "This part is to analyze the correlation between population density and economic status. We found the data for both population and area by each province. It needs to be calculated to population density first by dividing population by area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the population data from the most recent year available, which is 2018.\n",
    "We also need to change the column name to \"district\" to correspond with the area dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extract the population data by only year 2018\n",
    "population_2018 = population[population.columns[:2]]\n",
    "population_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now merge the population and area dataset by the province name. We choose to \"inner\" merge them because if there is a province with either no population or area, we are unable to calculate the population density.\n",
    "Then we could have calculate the population density by dividing population by area.\n",
    "The unit for population density is number of people per square kilometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge area data and population of 2018 by region\n",
    "popu_density = pd.merge(population_2018,area,on = 'Region')\n",
    "\n",
    "#calculate the population density\n",
    "popu_density['Area'] = pd.to_numeric(popu_density['Area'])\n",
    "popu_density['2018'] = pd.to_numeric(popu_density['2018'])\n",
    "popu_density['population density'] = popu_density['2018']/popu_density['Area']\n",
    "popu_density = popu_density.drop(columns = 'Area')\n",
    "popu_density = popu_density.drop(columns = '2018')\n",
    "popu_density.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now merge the data for population density and economic status by province. Since we use the population data in 2018 for calculating the population density, we will also use GRP in 2018 to find the correlation between population density and economic status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge population density data with GRP by region\n",
    "co_pd_es = pd.merge(popu_density,GRP, on = 'Region')\n",
    "co_pd_es = co_pd_es[co_pd_es.columns[:3]]\n",
    "#rename the 2018 GRP column\n",
    "co_pd_es = co_pd_es.rename(columns = {'2018':'GRP'})\n",
    "co_pd_es.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we look into the correlation between population density and GRP to see if they're actually correlated. We use the Pasty statsmodel to quantify our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_pd_es = co_pd_es.rename(columns = {'population density':'density'})\n",
    "#we want to see how well does population density and GRP correlate using pasty\n",
    "outcome, predictors = patsy.dmatrices('density ~ GRP', co_pd_es)\n",
    "# Now use statsmodels to intialize an OLS linear model\n",
    "#  This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "# fit the model\n",
    "res = mod.fit()\n",
    "# Check out the results\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the coefficient and R-squared value above, there's a positive relationship between population density and region gross product. \n",
    "\n",
    "Now we can visualize the correlation between population density and GRP . we will make a scatter plot of GRP vs. population density and draw the linear regression line to show the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the coefficient for the fit line using polyfit\n",
    "a1 = np.polyfit(co_pd_es['density'],co_pd_es['GRP'],deg = 1)[0]\n",
    "b1 = np.polyfit(co_pd_es['density'],co_pd_es['GRP'],deg = 1)[1]\n",
    "a1,b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the original data\n",
    "plt.scatter(co_pd_es['density'],co_pd_es['GRP'],alpha =0.3, label = 'Data')\n",
    "\n",
    "#Generate and plot the model fit line\n",
    "pred_GRP = co_pd_es['density']*a1+b1\n",
    "plt.plot(co_pd_es['density'],pred_GRP,'--k',label = 'Model')\n",
    "\n",
    "plt.title('GRP vs. Population Density by Province')\n",
    "plt.xlabel(\"population density \\n number of people per square km\" )\n",
    "plt.ylabel(\"GRP (yuan)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, it is clear that there is a positive relationship between population density and GRP. The regions with higher population density tend to have higher GRP. Thus, population density might also serve as a factor that confounds with the economic status. \n",
    "\n",
    "With better GRP, the province are expected to have a slower breakout rate due to the the better infrastructures like hospitals or clinics to support the citizens against the cirus. However, the breakout rates are actually tend to be higher with province with higher GRP. Population density might be the most important cofounding factor for this controversy. \n",
    "\n",
    "Now, we will look at the correlation between population density and the virus breakout rate to see whether they are in fact correlated.\n",
    "\n",
    "## correlation between population density and maximum infection percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge population density data with virus breakout rate by region\n",
    "PD_virus = pd.merge(popu_density, max_infection_percentage_1, on = 'Region')\n",
    "#rename the population density column\n",
    "PD_virus = PD_virus.rename(columns = {'population density':'PD'})\n",
    "PD_virus.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an Ordinary Least Squares model to find the correlation between population density and the virus breakout rate in 2018 for each provinces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the outcome and what we use to predict using pasty\n",
    "npvoutcome1, npvpredictors1 = patsy.dmatrices('max~ PD',PD_virus)\n",
    "#now use statsmodels to initialize an OLS linear model\n",
    "#this step initializes the model, and provides the data without actually computes the model\n",
    "mod_PD = sm.OLS(npvoutcome1,npvpredictors1)\n",
    "#fit the model\n",
    "res_PD = mod_PD.fit()\n",
    "#check out the results\n",
    "print(res_PD.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation seems vague because we have a large p-value of 0.859."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to find the correlation again while exclude the case of \"Hubei\" province just as in the above section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop observation in Hubei\n",
    "PD_virus = PD_virus[PD_virus.Region != 'Hubei']\n",
    "#set up the outcome and what we use to predict using pasty\n",
    "npvo1, npvp1 = patsy.dmatrices('max ~ PD', PD_virus)\n",
    "# Now use statsmodels to intialize an OLS linear model\n",
    "# This step initializes the model, and provides the data (but not actually compute the model)\n",
    "mod_PD_dropped = sm.OLS(npvo1, npvp1)\n",
    "# fit the model\n",
    "res_PD_dropped = mod_PD_dropped.fit()\n",
    "# Check out the results\n",
    "print(res_PD_dropped.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpret results from OLS model\n",
    "\n",
    "As we can see here, p-value here is 0.029, smaller than the general alpha value of 0.05. Therefore we can reject the hypothesis that population density is not correlated with maximum infection percentage of a region. It's statistically significant to conclude that the maximum infection percentage of an area is correlated with population density per capita in that area. In such case, we confirm that the population density serve as a cofactor that contributes to the correlation between GRP and maximum infection percentage.\n",
    "\n",
    "Now we visualize such relationship between population density in 2018 to the breakout rate of COVID-19.\n",
    "\n",
    "Use polyfit to fit a 1-degree linear model, predicting virus breakout rate from population density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the orginal data (as before)\n",
    "plt.scatter(PD_virus['PD'], PD_virus['max'], alpha=0.3, label='Data');\n",
    "\n",
    "# Generate and plot the model fit line\n",
    "# use the coefficient from OLS summary above\n",
    "PDmodel = PD_virus['PD']*4.635e-5 \n",
    "plt.plot(PD_virus['PD'],PDmodel,'--k',label = 'Model')\n",
    "\n",
    "plt.xlabel('population density \\n number of people per square km')\n",
    "plt.ylabel('Maximum Infected percentage \\n %')\n",
    "plt.legend()\n",
    "plt.ylim()\n",
    "plt.ylim(top = 0.00003)\n",
    "plt.ylim(bottom = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your ethics & privacy discussion here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
