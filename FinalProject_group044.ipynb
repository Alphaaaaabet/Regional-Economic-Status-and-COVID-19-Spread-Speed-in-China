{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that PIDs will be scraped from the public submission, but student names will be included.)\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [ x ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your overview here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Yang Li\n",
    "- Yiou Lyu\n",
    "- Linfeng Hu\n",
    "- Ruby Celeste Marroquin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A15560579\n",
    "- A15930345\n",
    "- A15473121\n",
    "- A16094382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the regional economic status of each province in mainland China correlate to its breakout and recovery of COVID-19?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your background and prior work here* \n",
    "\n",
    "References (include links):\n",
    "- 1)\n",
    "- 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your hypotheses here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Copy this information for each dataset)\n",
    "- Dataset Name: \n",
    "- Link to the dataset:\n",
    "- Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with codecs.open('Data/virus.json', 'r', 'utf-8') as data_file:\n",
    "    #data_teacher = json.load(data_file, 'utf-8')\n",
    "\n",
    "#topic[worksheet] = data_teacher[worksheetID]['Topic']\n",
    "#out = codecs.open('Worksheet.csv', 'w', 'utf-8')\n",
    "#out.write(topic[worksheet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean our data, our general approach is to represent datasets in pandas dataframe. Then we drop irrelevant information or outliers in data. We also rename the columns to make it easier for later analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we deal with the datasets that consist of economic status data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the income per capita value for each province in mainland China. Income is measured in yuan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Income = pd.read_csv('Data/Income.csv')\n",
    "Income = Income.dropna(axis=1, how='all')\n",
    "Income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the per capita Gross Regional Product value for each province. GRP per capita is measured in yuan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRP = pd.read_csv('Data/GRP.csv')\n",
    "GRP = GRP.dropna(axis=1, how='all')\n",
    "GRP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we move on to clean the population density related datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population per province here is calculated in the unit of 10000 persons). It includes all residents (permanent and temporary, rural and urban)at the end of that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('Data/Population.csv')\n",
    "population = population.dropna(axis = 1, how = 'all')\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate population density of a region, we also need to areas of each province. Here, area of each province is measured in unit of square kilometers.\n",
    "\n",
    "Since we only need the area information of each separate region, we will drop the \"Toal\" row at the end which contains information about the total area of China(judging by the data contained, the row name should be a typo). We will also drop the proportion row because we only need the area number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv('Data/Area.csv')\n",
    "area = area.dropna(axis = 1, how = 'all')\n",
    "#shorten column names to make following analysis simpler\n",
    "area = area.rename(columns={\"Area (sq.km)\": \"Area\"})\n",
    "area = area[area.District != 'Toal']\n",
    "area = area[area.columns[:2]]\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to remove \",\" in the string in order to change it to type int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comma(strin):\n",
    "    strin = strin.replace(',','')\n",
    "    return strin\n",
    "\n",
    "area['Area']= area['Area'].apply(remove_comma)\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read virus data into dataframes \n",
    "\n",
    "list_of_virus_data = list()\n",
    "\n",
    "# append data between Feb 1 and Feb 25 to list\n",
    "for i in range(20200201,20200226): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df.headers = path\n",
    "    list_of_virus_data.append(df)\n",
    "    \n",
    "# File 20200226.csv is missing, reason unknow. \n",
    "\n",
    "    \n",
    "# append data between Feb 27 and Feb 29 to list\n",
    "for i in range(20200227,20200230): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df.headers = path\n",
    "    list_of_virus_data.append(df)\n",
    "\n",
    "# append data between Mar 1 and  Mar 1 to list\n",
    "for i in range(20200301,20200302): \n",
    "    path = './Data/virus/' + str(i) + '.csv'\n",
    "    list_of_virus_data.append(pd.read_csv(path))\n",
    "    \n",
    "print('number of dataframes for virus: ',len(list_of_virus_data))\n",
    "\n",
    "# access ith elment in the list using list_of_virus_data[i]\n",
    "# for example list_of_virus_data[0] gives the first dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start cleaning virus data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 0th to 1th df in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 0th to 1th df in the list \n",
    "for i in range(0,2):\n",
    "    # get the df of the ith day\n",
    "    df = list_of_virus_data[i]\n",
    "    # use the first data row as column names\n",
    "    df.columns = df.iloc[0]\n",
    "    # drop first row, because is was used as header\n",
    "    df = df.drop(0)\n",
    "    # drop the column '1', because it is irrlavent\n",
    "    df = df.drop(1, axis=1)\n",
    "    # save cleaned data to list_of_virus_data \n",
    "    list_of_virus_data[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 2th df in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean 2th df in the list\n",
    "# get the df of the ith day\n",
    "df = list_of_virus_data[2]\n",
    "# reset column names\n",
    "df.columns = [\"Province/Region/City\", \"Confirmed Cases\", 1]\n",
    "# drop meaningless 1\" column,  keep \"Confirmed Cases\" and \"Province/Region/City\"\n",
    "df = df.drop(1, axis=1)\n",
    "# Drop the last row, because it is comment instaed of data\n",
    "df = df.drop(df.shape[0] - 1)\n",
    "# save cleaned data to list_of_virus_data \n",
    "list_of_virus_data[2] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 3th to 10th df in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 3th to 10th df in the list \n",
    "for i in range(3,11):\n",
    "    # get the df of the ith day\n",
    "    df = list_of_virus_data[i]\n",
    "    # use the first data row as column names\n",
    "    df.columns = df.iloc[0]\n",
    "    # drop first row, because is was used as header\n",
    "    df = df.drop(0)\n",
    "    # drop the column '1', because it is irrlavent\n",
    "    df = df.drop(1, axis=1)\n",
    "    # save cleaned data to list_of_virus_data\n",
    "    list_of_virus_data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = list_of_virus_data[1]\n",
    "df2 = list_of_virus_data[2]\n",
    "df1.merge(df2,how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Clean 11th to the 28th df in the list \n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between Population density and economic status\n",
    "This part is to analyze the correlation between population density and economic status. We found the data for both population and area by each province. It needs to be calculated to population density first by dividing population by area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the population data from the most recent year available, which is 2018.\n",
    "We also need to change the column name to \"district\" to correspond with the area dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2018 = population[population.columns[:2]]\n",
    "population_2018 = population_2018.rename(columns = {'Region':'District'})\n",
    "population_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now merge the population and area dataset by the province name. We choose to \"inner\" merge them because if there is a province with either no population or area, we are unable to calculate the population density.\n",
    "Then we could have calculate the population density by dividing population by area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popu_density = pd.merge(population_2018,area,on = 'District')\n",
    "popu_density['Area'] = pd.to_numeric(popu_density['Area'])\n",
    "popu_density['2018'] = pd.to_numeric(popu_density['2018'])\n",
    "popu_density['population density'] = popu_density['2018']/popu_density['Area']\n",
    "popu_density = popu_density.drop(columns = 'Area')\n",
    "popu_density = popu_density.drop(columns = '2018')\n",
    "popu_density.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your ethics & privacy discussion here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
